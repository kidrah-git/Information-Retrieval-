{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26c7f336-f712-4654-ac28-b338014fe9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41fb4414-c519-414c-abd2-0595b8ca67d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_files(folder_path):\n",
    "    data = {}\n",
    "    doc_id_to_filename = {}\n",
    "    doc_id = 0\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as file:\n",
    "                data[doc_id] = file.read()\n",
    "                doc_id_to_filename[doc_id] = filename\n",
    "                logging.info(f\"Loaded file: {filename} with doc_id: {doc_id}\")\n",
    "                doc_id += 1\n",
    "    return data, doc_id_to_filename\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb5a575b-ba18-4396-9ae3-4eb558e9a6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return text.lower().split()\n",
    "    import re\n",
    "    return re.findall(r'\\b\\w+\\b', text.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "776ca347-6aad-4dda-b898-871c6fd0e702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_frequency(term, document):\n",
    "    return document.count(term) / len(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b4d4c3d-4452-4ab9-ad7a-47f9dd4ac8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_document_frequency(term, all_documents):\n",
    "    num_docs_containing_term = sum(1 for doc in all_documents if term in doc)\n",
    "    return math.log(len(all_documents) / (1 + num_docs_containing_term))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07c0ec88-49db-4fbd-a309-b60493542d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tfidf(document, all_documents, vocab):\n",
    "    tfidf_vector = []\n",
    "    for term in vocab:\n",
    "        tf = term_frequency(term, document)\n",
    "        idf = inverse_document_frequency(term, all_documents)\n",
    "        tfidf_vector.append(tf * idf)\n",
    "    return np.array(tfidf_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aad5c3f2-b0b8-43f2-ad92-fcc129bdbf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2) if norm_vec1 * norm_vec2 != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ad9643d-4bad-41ae-8d94-e2ae950c4091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[('Champions Leauge', [(0, 0.13018891098082389)])]\n",
      "[('Champions Leauge', [(0, 0.13018891098082389)]), ('Laliga', [(0, 0.09205746178983235)])]\n",
      "[('Champions Leauge', [(0, 0.13018891098082389)]), ('Laliga', [(0, 0.09205746178983235)]), ('Barcelona', [(0, 0.09205746178983235)])]\n",
      "[('Champions Leauge', [(0, 0.13018891098082389)]), ('Laliga', [(0, 0.09205746178983235)]), ('Barcelona', [(0, 0.09205746178983235)]), ('Cristiano Ronaldo', [(0, 0.13018891098082389)])]\n",
      "[('Champions Leauge', [(0, 0.13018891098082389)]), ('Laliga', [(0, 0.09205746178983235)]), ('Barcelona', [(0, 0.09205746178983235)]), ('Cristiano Ronaldo', [(0, 0.13018891098082389)]), ('RealMadrid', [(0, 0.09205746178983235)])]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    folder_path = \"/Users/haddiphuel/Desktop/Real Madrid \"\n",
    "\n",
    "    docs, doc_id_to_filename = load_text_files(folder_path)\n",
    "\n",
    "    queries = [\"Champions Leauge\",\n",
    "               \"Laliga\",\n",
    "               \"Barcelona\",\n",
    "               \"Cristiano Ronaldo\",\n",
    "               \"RealMadrid\"]\n",
    "\n",
    "    tokenized_docs = [tokenize(doc) for doc in docs.values()]\n",
    "\n",
    "    vocab = sorted(set(word for doc in tokenized_docs for word in doc))\n",
    "    print(logging.info(f\"Vocabulary size: {len(vocab)}\"))\n",
    "\n",
    "    doc_tfidf_vectors = [compute_tfidf(doc, tokenized_docs, vocab) for doc in tokenized_docs]\n",
    "\n",
    "    results = []\n",
    "    for query in queries:\n",
    "        tokenized_query = tokenize(query)\n",
    "        query_tfidf_vector = compute_tfidf(tokenized_query, tokenized_docs, vocab)\n",
    "\n",
    "        similarities = []\n",
    "        for doc_id, doc_vector in enumerate(doc_tfidf_vectors):\n",
    "            similarity = cosine_similarity(query_tfidf_vector, doc_vector)\n",
    "            similarities.append((doc_id, similarity))\n",
    "\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        results.append((query, similarities))\n",
    "\n",
    "        print(results)\n",
    "\n",
    "    path = \"/Users/haddiphuel/Desktop/Real Madrid \"\n",
    "    output_file = os.path.join(path, \"/Users/haddiphuel/Desktop/Real Madrid /result.txt\")\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for query, similarities in results:\n",
    "            f.write(f\"Query: {query}\\n\")\n",
    "            for doc_id, similarity in similarities:\n",
    "                filename = doc_id_to_filename[doc_id]\n",
    "                f.write(f\"  Document: {filename}, Similarity: {similarity:.4f}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    logging.info(f\"Results written to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26bdda9b-d20e-491c-a237-832b8596b458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[('Champions Leauge', [(0, 0.12909944487358058)])]\n",
      "[('Champions Leauge', [(0, 0.12909944487358058)]), ('Laliga', [(0, 0.09128709291752768)])]\n",
      "[('Champions Leauge', [(0, 0.12909944487358058)]), ('Laliga', [(0, 0.09128709291752768)]), ('Barcelona', [(0, 0.09128709291752768)])]\n",
      "[('Champions Leauge', [(0, 0.12909944487358058)]), ('Laliga', [(0, 0.09128709291752768)]), ('Barcelona', [(0, 0.09128709291752768)]), ('Cristiano Ronaldo', [(0, 0.12909944487358058)])]\n",
      "[('Champions Leauge', [(0, 0.12909944487358058)]), ('Laliga', [(0, 0.09128709291752768)]), ('Barcelona', [(0, 0.09128709291752768)]), ('Cristiano Ronaldo', [(0, 0.12909944487358058)]), ('RealMadrid', [(0, 0.09128709291752768)])]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1c0de3-06ec-4a27-8366-a5b0e8bc8547",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
